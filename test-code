# to run 
# scrapy crawl basketballref_spider -o stats.csv

import scrapy

class basketballrefSpider(scrapy.Spider):
    name = 'basketballref_spider'
    
    start_urls = ['https://www.basketball-reference.com']
    
    def parse(self, response):
        '''
        Hardcode from initial homepage to players page.
        Call parse_players function on players page.
        
        No output. 
        '''
        players_url = response.url + "/players" # use to navigate to players page
        yield scrapy.Request(players_url, callback = self.parse_players) # callback next function
        
    def parse_players(self,response):
        '''
        Begin at players page, collect links to pages showing lists of all nba players by letter of last name
        For each group of players, call next function.
        
        No output.
        '''
        # create list of players links
        players_list = ['https://www.basketball-reference.com' + a.attrib['href'] for a in response.css('ul.alphabet li a')] 
        for players in players_list:
            yield scrapy.Request(players, callback = self.parse_players_stats) # callback next function for each player list  
            
    def parse_players_stats(self,response):
        player_name = response.css("div h1 span::text").get()
        stats = response.css("h2.title a::text").getall()
        for stat in stats:
            yield {'player': player_name, 'stat': stat}     
            
